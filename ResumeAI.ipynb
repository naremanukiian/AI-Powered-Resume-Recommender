{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *AI-Powered Resume Recommendation System with Streamlit and OpenAI Integration*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This project creates an AI-powered resume recommendation system using OpenAI's GPT-3.5 model, Streamlit for the user interface, and ngrok for exposing the app to the internet. Users can paste their resume and a job description into the app to receive tailored recommendations. The system analyzes the input and generates suggestions for resume improvements, matching skills, and the best type of resume for the job. The project demonstrates a seamless integration of AI, interactive web interfaces, and cloud tunneling services to make the tool accessible online. The app is hosted locally using Streamlit, and ngrok is used to create a public URL, making the app available to anyone via the internet."
      ],
      "metadata": {
        "id": "06K8_mk-s_Cc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Installing Required Libraries\n",
        "This section installs the necessary Python libraries for the project. It uses the pip command to install streamlit for building the web app, pyngrok for creating a secure tunnel to make the app accessible over the internet, and openai for integrating OpenAI's GPT API for resume analysis and recommendations. The -q flag ensures the installation is quiet, suppressing unnecessary output."
      ],
      "metadata": {
        "id": "a2BR3cQorDT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok openai"
      ],
      "metadata": {
        "id": "NNF9N1tpn2yy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Defining the Streamlit App and OpenAI Integration\n",
        "In this section, the core logic of the AI-powered resume recommendation system is implemented. The code uses streamlit to create a user interface that allows the user to input their resume/profile and job description. It also integrates OpenAI's API to generate a tailored resume recommendation based on the input. The OpenAI client is initialized with the provided API key, and a button is created to trigger the recommendation generation. The system formulates a prompt for OpenAI's GPT model to analyze the inputs and provide insights such as resume type, matching skills, improvement suggestions, and a detailed explanation. The st.spinner shows a loading indicator while the API processes the request, and any errors are handled with exception handling to ensure smooth user experience."
      ],
      "metadata": {
        "id": "f2VV9t8GrPs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from openai import OpenAI\n",
        "import traceback\n",
        "\n",
        "client = OpenAI(api_key=\"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\")\n",
        "\n",
        "st.title(\"ðŸ“„ AI-Powered Resume Recommendation System\")\n",
        "st.markdown(\"Paste your resume/profile and the job description to get tailored resume suggestions.\")\n",
        "\n",
        "profile_text = st.text_area(\"Your Profile\", height=150, placeholder=\"Paste your profile here...\")\n",
        "job_text = st.text_area(\"Job Description\", height=150, placeholder=\"Paste the job description here...\")\n",
        "\n",
        "if st.button(\"Generate Recommendation\"):\n",
        "    with st.spinner(\"Analyzing and generating recommendation...\"):\n",
        "        try:\n",
        "            prompt = f\"\"\"\n",
        "            You are an AI assistant helping someone choose the best version of their resume.\n",
        "\n",
        "            User Profile:\n",
        "            \\\"\\\"\\\"{profile_text}\\\"\\\"\\\"\n",
        "\n",
        "            Job Description:\n",
        "            \\\"\\\"\\\"{job_text}\\\"\\\"\\\"\n",
        "\n",
        "            Provide:\n",
        "            1. Recommended Resume Type\n",
        "            2. Matching Skills\n",
        "            3. Ways to Improve Resume\n",
        "            4. Explanation\n",
        "            \"\"\"\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=500,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            result = response.choices[0].message.content.strip()\n",
        "            st.markdown(\"### ðŸ§  Resume Recommendation\")\n",
        "            st.markdown(result)\n",
        "        except Exception as e:\n",
        "            st.error(\"âš ï¸ Something went wrong. Please check the API key or your input.\")\n",
        "            st.text(traceback.format_exc())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlwU8U2zn3Yi",
        "outputId": "50dd23dc-502d-4d74-e38c-e5e3fa3cc9f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Setting Up ngrok Authentication\n",
        "In this section, the pyngrok library is used to create a secure tunnel to the Streamlit app, enabling it to be accessed externally via a public URL. The authentication token for ngrok is set using the provided token, which allows the app to be exposed through a public URL. This is essential for sharing the app with others over the internet, even though it's running locally on the user's machine. The set_auth_token function configures the ngrok client with the necessary credentials for establishing the tunnel."
      ],
      "metadata": {
        "id": "ALRqF8MbrhEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"2w82GBTpgkbwyYVF7fyEBNGZ9s5_5gMFC9zDxTDC51nSbh2XC\")"
      ],
      "metadata": {
        "id": "zTQ6-8WyoBy5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Running Streamlit App in a Separate Thread and Creating ngrok Tunnel\n",
        "This section initiates the Streamlit app in a separate thread to avoid blocking the main execution of the code. The threading module is used to run the Streamlit app (app.py) in the background on port 8501. After starting the app, the script waits for 5 seconds to allow the app to fully initialize before creating the ngrok tunnel. The ngrok.connect method is used to expose the local app to the public by generating a public URL. This URL can then be used to access the app from anywhere. The print statement outputs the public URL where the app is live."
      ],
      "metadata": {
        "id": "S4GacWTrruno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Function to run Streamlit app\n",
        "def run():\n",
        "    !streamlit run app.py --server.port 8501\n",
        "\n",
        "# Start Streamlit app in a separate thread\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "\n",
        "# Wait for the app to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel\n",
        "public_url = ngrok.connect(addr=8501, proto=\"http\")\n",
        "print(f\"ðŸŒ Your app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCXGuskVoE9p",
        "outputId": "ee5b1233-4dd9-493b-8e5c-bb77e55ea807"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-04-24 12:12:25.899 Port 8501 is already in use\n",
            "ðŸŒ Your app is live at: NgrokTunnel: \"https://8ad5-34-125-78-93.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}